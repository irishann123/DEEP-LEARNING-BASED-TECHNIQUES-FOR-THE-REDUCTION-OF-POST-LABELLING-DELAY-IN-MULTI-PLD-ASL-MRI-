# -*- coding: utf-8 -*-
"""trying.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aHvfQBY6_Mt_wp2Qbar7N-3GnNwyuWui
"""

import os  # Import the os module to use listdir

# Update the data path to your local path
data_path = '/home/labadmin/multiPLD/mridata'

# Check if the directory exists
if os.path.exists(data_path):
    print(f"Path '{data_path}' exists.")
    # List the files in the directory
    files = os.listdir(data_path)  # Get the list of files
    if files:
        print("Files in dataset folder:", files)
    else:
        print("The folder is empty.")
else:
    print(f"Path '{data_path}' does not exist. Please check the directory path.")

# Function to load and preprocess data
def load_and_preprocess_hdf5(file_path):
    with h5py.File(file_path, 'r') as file:
        data_group = file['data_phantom_noisy']

        # Load datasets
        pwi = np.array(data_group['PWI_images'])  # Shape: (3, 60, 60, 72)
        cbf = np.array(data_group['CBF_groundtruth'])  # Shape: (60, 60, 72)
        att = np.array(data_group['ATT_groundtruth'])  # Shape: (60, 60, 72)

        # Transpose PWI to match (batch, height, width, channels)
        pwi = np.transpose(pwi, (1, 2, 3, 0))

        # Normalize PWI, CBF, and ATT
        pwi = (pwi - np.min(pwi)) / (np.max(pwi) - np.min(pwi))
        cbf = (cbf - np.min(cbf)) / (np.max(cbf) - np.min(cbf))
        att = (att - np.min(att)) / (np.max(att) - np.min(att))

    return pwi, cbf, att

import os
import numpy as np
import h5py

# Load and preprocess data

pwi_subjects, cbf_subjects, att_subjects = [], [], []
for file_name in files:
    file_path = os.path.join(data_path, file_name)
    pwi, cbf, att = load_and_preprocess_hdf5(file_path)
    pwi_subjects.append(pwi)
    cbf_subjects.append(cbf)
    att_subjects.append(att)

# Convert lists to numpy arrays
pwi_subjects = np.array(pwi_subjects)
cbf_subjects = np.array(cbf_subjects)
att_subjects = np.array(att_subjects)

import numpy as np
import sklearn
print("NumPy version:", np.__version__)
print("Scikit-learn version:", sklearn.__version__)

from sklearn.model_selection import train_test_split

# Split data into training and testing sets
X_train, X_test, y_train_cbf, y_test_cbf, y_train_att, y_test_att = train_test_split(
    pwi_subjects, cbf_subjects, att_subjects, test_size=4/24, random_state=42
)

# Print shapes for verification
print("Training PWI shape:", X_train.shape)
print("Testing PWI shape:", X_test.shape)
print("Training CBF shape:", y_train_cbf.shape)
print("Testing CBF shape:", y_test_cbf.shape)
print("Training ATT shape:", y_train_att.shape)
print("Testing ATT shape:", y_test_att.shape)

import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.optimizers import Adam
import numpy as np
import matplotlib.pyplot as plt
from skimage.metrics import structural_similarity as ssim

# Attention mechanism block (Simple attention)
def attention_block(input_tensor, filters):
    attention = layers.Conv3D(filters, (1, 1, 1), activation='sigmoid', padding='same')(input_tensor)
    return layers.multiply([input_tensor, attention])

# Define VGG-like model with attention mechanism
def vgg_attention_model(input_shape):
    inputs = layers.Input(shape=input_shape)

    # Encoder (VGG-like structure with attention mechanism)
    c1 = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same')(c1)
    c1 = attention_block(c1, 32)  # Attention applied after convolution
    p1 = layers.MaxPooling3D((2, 2, 2))(c1)

    c2 = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(p1)
    c2 = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c2)
    c2 = attention_block(c2, 64)
    p2 = layers.MaxPooling3D((2, 2, 2))(c2)

    c3 = layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same')(p2)
    c3 = layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c3)
    c3 = attention_block(c3, 128)

    # Decoder
    u4 = layers.Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c3)
    u4 = layers.concatenate([u4, c2])
    c4 = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(u4)
    c4 = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c4)
    c4 = attention_block(c4, 64)

    u5 = layers.Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(c4)
    u5 = layers.concatenate([u5, c1])
    c5 = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same')(u5)
    c5 = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same')(c5)
    c5 = attention_block(c5, 32)

    # Output heads
    output_cbf = layers.Conv3D(1, (1, 1, 1), activation='linear', name="CBF")(c5)
    output_att = layers.Conv3D(1, (1, 1, 1), activation='linear', name="ATT")(c5)

    model = Model(inputs, [output_cbf, output_att])
    return model

# Initialize the model
model = vgg_attention_model(input_shape=(60, 60, 72, 3))

# SSIM and PSNR metrics functions
def ssim_loss(y_true, y_pred):
    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

def psnr_loss(y_true, y_pred):
    return tf.reduce_mean(tf.image.psnr(y_true, y_pred, max_val=1.0))

def accuracy_metric(y_true, y_pred, threshold=0.5):
    if y_pred.shape[-1] == 1:  # Only squeeze if last dimension is 1
        y_pred = tf.squeeze(y_pred, axis=-1)

    y_pred = tf.cast(y_pred > threshold, tf.float32)  # Apply threshold
    correct = tf.equal(y_true, y_pred)
    return tf.reduce_mean(tf.cast(correct, tf.float32))


def ssim_metric(y_true, y_pred):
    # Ensure y_pred has the correct shape before computing SSIM
    if y_pred.shape[-1] == 1:  # Only squeeze if the last dimension is 1
        y_pred = tf.squeeze(y_pred, axis=-1)

    return tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

def psnr_metric(y_true, y_pred):
    # Ensure y_pred has the correct shape before processing
    if y_pred.shape[-1] == 1:
        y_pred = tf.squeeze(y_pred, axis=-1)  # Squeeze only if last dim is 1

    return tf.image.psnr(y_true, y_pred, max_val=1.0)

# Lin's Concordance Correlation Coefficient (CCC)
def ccc_metric(y_true, y_pred):
    # Flatten the tensors to 1D arrays for computation
    y_true_flat = tf.reshape(y_true, [-1])
    y_pred_flat = tf.reshape(y_pred, [-1])

    # Mean of the true and predicted values
    mean_true = tf.reduce_mean(y_true_flat)
    mean_pred = tf.reduce_mean(y_pred_flat)

    # Covariance between true and predicted
    covariance = tf.reduce_mean((y_true_flat - mean_true) * (y_pred_flat - mean_pred))

    # Variance of the true and predicted values
    var_true = tf.reduce_mean(tf.square(y_true_flat - mean_true))
    var_pred = tf.reduce_mean(tf.square(y_pred_flat - mean_pred))

    # Calculate CCC
    ccc = (2 * covariance) / (var_true + var_pred + tf.square(mean_true - mean_pred))

    return ccc

# Re-compile the model with the added metrics, including ccc_metric
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss={'CBF': 'mean_squared_error', 'ATT': 'mean_squared_error'},
    metrics={
        'CBF': ['mse', ssim_metric, psnr_metric, accuracy_metric, ccc_metric],
        'ATT': ['mse', ssim_metric, psnr_metric, accuracy_metric, ccc_metric]
    }
)

# Training the model
history = model.fit(
    X_train, [y_train_cbf, y_train_att],
    validation_data=(X_test, [y_test_cbf, y_test_att]),
    epochs=2000,
    batch_size=2,
    verbose=1
)

# Evaluate the model
evaluation = model.evaluate(X_test, [y_test_cbf, y_test_att], verbose=1)
print("Evaluation Results:", evaluation)

# Extract the metrics from evaluation results
metrics_names = [
    "CBF_Loss", "CBF_MSE", "ATT_MSE", "CBF_Accuracy", "ATT_Accuracy",
    "CBF_PSNR", "ATT_PSNR", "CBF_SSIM", "ATT_SSIM"
]

# Print metrics in a readable format
print("\nFinal Evaluation Metrics:")
for name, value in zip(metrics_names, evaluation):
    print(f"{name}: {value:.4f}")



import matplotlib.pyplot as plt
import numpy as np

# Select the test subject index
test_subject_index = 0

# Select the slices to visualize
slices = [19, 23, 26]

# Create a figure with subplots
fig, axes = plt.subplots(1, len(slices), figsize=(15, 5))

# Plot each slice
for i, slice_index in enumerate(slices):
    input_image = X_test[test_subject_index][slice_index]

    # Ensure the image is grayscale (in case it has multiple channels)
    if input_image.ndim == 3:  # If it's a color image, take the mean across channels
        input_image = np.mean(input_image, axis=-1)

    # Normalize to [0, 1] if required
    input_image = np.clip(input_image, 0, 1)

    # Display the image
    axes[i].imshow(input_image, cmap='gray', interpolation='none')
    axes[i].set_title(f'Slice {slice_index}')
    axes[i].axis('off')

plt.show()