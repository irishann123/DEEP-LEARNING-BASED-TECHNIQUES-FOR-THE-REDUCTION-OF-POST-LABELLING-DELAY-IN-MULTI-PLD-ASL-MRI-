# -*- coding: utf-8 -*-
"""iory.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dERG-Lcq15G3YG8cTItnpGAMtvzXlzl2
"""

import os  # Import the os module to use listdir

# Update the data path to your local path
data_path = '/home/labadmin/multiPLD/mridata'

# Check if the directory exists
if os.path.exists(data_path):
    print(f"Path '{data_path}' exists.")
    # List the files in the directory
    files = os.listdir(data_path)  # Get the list of files
    if files:
        print("Files in dataset folder:", files)
    else:
        print("The folder is empty.")
else:
    print(f"Path '{data_path}' does not exist. Please check the directory path.")

# Function to load and preprocess data
def load_and_preprocess_hdf5(file_path):
    with h5py.File(file_path, 'r') as file:
        data_group = file['data_phantom_noisy']

        # Load datasets
        pwi = np.array(data_group['PWI_images'])  # Shape: (3, 60, 60, 72)
        cbf = np.array(data_group['CBF_groundtruth'])  # Shape: (60, 60, 72)
        att = np.array(data_group['ATT_groundtruth'])  # Shape: (60, 60, 72)

        # Transpose PWI to match (batch, height, width, channels)
        pwi = np.transpose(pwi, (1, 2, 3, 0))

        # Normalize PWI, CBF, and ATT
        pwi = (pwi - np.min(pwi)) / (np.max(pwi) - np.min(pwi))
        cbf = (cbf - np.min(cbf)) / (np.max(cbf) - np.min(cbf))
        att = (att - np.min(att)) / (np.max(att) - np.min(att))

    return pwi, cbf, att

import os
import numpy as np
import h5py

# Load and preprocess data

pwi_subjects, cbf_subjects, att_subjects = [], [], []
for file_name in files:
    file_path = os.path.join(data_path, file_name)
    pwi, cbf, att = load_and_preprocess_hdf5(file_path)
    pwi_subjects.append(pwi)
    cbf_subjects.append(cbf)
    att_subjects.append(att)

# Convert lists to numpy arrays
pwi_subjects = np.array(pwi_subjects)
cbf_subjects = np.array(cbf_subjects)
att_subjects = np.array(att_subjects)

import numpy as np
import sklearn
print("NumPy version:", np.__version__)
print("Scikit-learn version:", sklearn.__version__)

from sklearn.model_selection import train_test_split

# Split data into training and testing sets
X_train, X_test, y_train_cbf, y_test_cbf, y_train_att, y_test_att = train_test_split(
    pwi_subjects, cbf_subjects, att_subjects, test_size=4/24, random_state=42
)

# Print shapes for verification
print("Training PWI shape:", X_train.shape)
print("Testing PWI shape:", X_test.shape)
print("Training CBF shape:", y_train_cbf.shape)
print("Testing CBF shape:", y_test_cbf.shape)
print("Training ATT shape:", y_train_att.shape)
print("Testing ATT shape:", y_test_att.shape)

import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.optimizers import Adam
import numpy as np
import matplotlib.pyplot as plt
from skimage.metrics import structural_similarity as ssim

import tensorflow as tf

def make_CBFNet(params):
    class MonteCarloDropout(tf.keras.layers.Dropout):
        def call(self, inputs, training=True):
            return super().call(inputs, training=training)

    model = tf.keras.Sequential()
    model.add(tf.keras.layers.Conv3D(params['conv-in_featN'], 3, padding='same', activation='relu', input_shape=params['input_shape']))

    for _ in range(params['num_conv_layers']):
        model.add(tf.keras.layers.Conv3D(params['conv_featN'], 3, padding='same', activation='relu', kernel_initializer='glorot_normal'))
        model.add(MonteCarloDropout(params['dropout']) if params['dropout_mc'] else tf.keras.layers.Dropout(rate=params['dropout']))

    model.add(tf.keras.layers.Conv3D(10, 3, padding='same', activation='relu'))
    model.add(MonteCarloDropout(rate=params['dropout']) if params['dropout_mc'] else tf.keras.layers.Dropout(rate=params['dropout']))
    model.add(tf.keras.layers.Conv3D(2, 2, padding='same', activation='relu'))

    return model

import tensorflow as tf
from tensorflow.keras.layers import Conv3D, Conv3DTranspose, Input, Concatenate, Dropout, BatchNormalization, ReLU, LeakyReLU, Layer

from tensorflow.keras.layers import Cropping3D
from tensorflow.keras.layers import ZeroPadding3D
def downsample(filters, size, strides, apply_batchnorm=True, apply_dropout=False, dropout_mc=False):
    class MonteCarloDropout(tf.keras.layers.Dropout):
        def call(self, inputs, training=True):
            return super().call(inputs, training=training)

    initializer = tf.keras.initializers.RandomNormal(0., 0.02)
    result = tf.keras.Sequential([
        tf.keras.layers.Conv3D(filters, size, strides=strides, padding='same', kernel_initializer=initializer, use_bias=False),
        tf.keras.layers.BatchNormalization() if apply_batchnorm else tf.keras.layers.Layer(),
        MonteCarloDropout(rate=0.3) if apply_dropout and dropout_mc else tf.keras.layers.Dropout(0.3) if apply_dropout else tf.keras.layers.Layer(),
        tf.keras.layers.LeakyReLU()
    ])
    return result

def upsample(filters, size, strides, apply_dropout=False, dropout_mc=False):
    class MonteCarloDropout(tf.keras.layers.Dropout):
        def call(self, inputs, training=True):
            return super().call(inputs, training=training)

    initializer = tf.keras.initializers.RandomNormal(0., 0.02)
    result = tf.keras.Sequential([
        tf.keras.layers.Conv3DTranspose(filters, size, strides=strides, padding='same', kernel_initializer=initializer, use_bias=False),
        tf.keras.layers.BatchNormalization(),
        MonteCarloDropout(rate=0.3) if apply_dropout and dropout_mc else tf.keras.layers.Dropout(0.3) if apply_dropout else tf.keras.layers.Layer(),
        tf.keras.layers.ReLU()
    ])
    return result
def make_uCBFNet(params):
    input_size = params['input_shape']

    inputs = Input(input_size)

    padded_inputs = ZeroPadding3D(padding=((2, 2), (2, 2), (0, 0)))(inputs)
    down_stack = [
        downsample(params['conv-n_in'], 3, (2,2,1), apply_batchnorm=False),
        downsample(20, 3, (2,2,1)),
        downsample(params['conv-n_deep'], 3, (2,2,1), apply_dropout=True)
    ]

    up_stack = [
        upsample(20, 3, (2,2,1), apply_dropout=True),
        upsample(10, 3, (2,2,1), apply_dropout=True)
    ]

    last_stack = [
        Conv3DTranspose(10, 3, strides=(2,2,1), padding='same', activation='relu')
    ]

    x = padded_inputs
    skips = []
    for down in down_stack:
        x = down(x)
        skips.append(x)

    skips = list(reversed(skips[:-1]))
    for up, skip in zip(up_stack, skips):
        x = up(x)
        if x.shape[1] != skip.shape[1] or x.shape[2] != skip.shape[2] or x.shape[3] != skip.shape[3]:
            x = Conv3DTranspose(skip.shape[-1], 3, strides=1, padding='same', activation='relu')(x)
        x = Concatenate()([x, skip])

    for layer in last_stack:
        x = layer(x)

    # Cropping from (64,64,72) to (60,60,72)
    x = Cropping3D(cropping=((2,2), (2,2), (0,0)))(x)

    # Two separate output heads
    output_cbf = Conv3D(1, 3, padding='same', activation='relu', name="CBF")(x)
    output_att = Conv3D(1, 3, padding='same', activation='relu', name="ATT")(x)

    return tf.keras.Model(inputs=inputs, outputs=[output_cbf, output_att])

params = {"input_shape": (60,60,72,3),
        "conv-n_in": 10,
        "conv-n_deep": 60,
        "loss_brain": 0.5,
        "lr": 0.0005,
        "dropout_mc": False}

# Construct the U-Net model
model = make_uCBFNet(params)

print(model.summary())
from tensorflow.keras.utils import plot_model

# Assuming your model is named unet
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True, expand_nested=True)

# SSIM and PSNR metrics functions
def ssim_loss(y_true, y_pred):
    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

def psnr_loss(y_true, y_pred):
    return tf.reduce_mean(tf.image.psnr(y_true, y_pred, max_val=1.0))

def accuracy_metric(y_true, y_pred, threshold=0.5):
    if y_pred.shape[-1] == 1:  # Only squeeze if last dimension is 1
        y_pred = tf.squeeze(y_pred, axis=-1)

    y_pred = tf.cast(y_pred > threshold, tf.float32)  # Apply threshold
    correct = tf.equal(y_true, y_pred)
    return tf.reduce_mean(tf.cast(correct, tf.float32))


def ssim_metric(y_true, y_pred):
    # Ensure y_pred has the correct shape before computing SSIM
    if y_pred.shape[-1] == 1:  # Only squeeze if the last dimension is 1
        y_pred = tf.squeeze(y_pred, axis=-1)

    return tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

def psnr_metric(y_true, y_pred):
    # Ensure y_pred has the correct shape before processing
    if y_pred.shape[-1] == 1:
        y_pred = tf.squeeze(y_pred, axis=-1)  # Squeeze only if last dim is 1

    return tf.image.psnr(y_true, y_pred, max_val=1.0)

# Lin's Concordance Correlation Coefficient (CCC)
def ccc_metric(y_true, y_pred):
    # Flatten the tensors to 1D arrays for computation
    y_true_flat = tf.reshape(y_true, [-1])
    y_pred_flat = tf.reshape(y_pred, [-1])

    # Mean of the true and predicted values
    mean_true = tf.reduce_mean(y_true_flat)
    mean_pred = tf.reduce_mean(y_pred_flat)

    # Covariance between true and predicted
    covariance = tf.reduce_mean((y_true_flat - mean_true) * (y_pred_flat - mean_pred))

    # Variance of the true and predicted values
    var_true = tf.reduce_mean(tf.square(y_true_flat - mean_true))
    var_pred = tf.reduce_mean(tf.square(y_pred_flat - mean_pred))

    # Calculate CCC
    ccc = (2 * covariance) / (var_true + var_pred + tf.square(mean_true - mean_pred))

    return ccc

# Re-compile the model with the added metrics, including ccc_metric
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss={'CBF': 'mean_squared_error', 'ATT': 'mean_squared_error'},
    metrics={
        'CBF': ['mse', ssim_metric, psnr_metric, accuracy_metric, ccc_metric],
        'ATT': ['mse', ssim_metric, psnr_metric, accuracy_metric, ccc_metric]
    }
)

# Training the model
history = model.fit(
    X_train, [y_train_cbf, y_train_att],
    validation_data=(X_test, [y_test_cbf, y_test_att]),
    epochs=2000,
    batch_size=2,
    verbose=1
)

# Get metric names
metric_names = model.metrics_names

# Evaluate the model
evaluation = model.evaluate(X_test, [y_test_cbf, y_test_att], verbose=1)

# Create a dictionary mapping metric names to values
evaluation_dict = dict(zip(metric_names, evaluation))

# Print the required metrics
print(f"CBF MSE: {evaluation_dict['CBF_mse']:.6f}, ATT MSE: {evaluation_dict['ATT_mse']:.6f}")
print(f"CBF SSIM: {evaluation_dict['CBF_ssim_metric']:.6f}, ATT SSIM: {evaluation_dict['ATT_ssim_metric']:.6f}")
print(f"CBF PSNR: {evaluation_dict['CBF_psnr_metric']:.6f}, ATT PSNR: {evaluation_dict['ATT_psnr_metric']:.6f}")
print(f"CBF CCC: {evaluation_dict['CBF_ccc_metric']:.6f}, ATT CCC: {evaluation_dict['ATT_ccc_metric']:.6f}")


# Extract the metrics from evaluation results
#metrics_names = [
#   "CBF_Loss", "CBF_MSE", "ATT_MSE", "CBF_Accuracy", "ATT_Accuracy",
#    "CBF_PSNR", "ATT_PSNR", "CBF_SSIM", "ATT_SSIM"
#]

# Print metrics in a readable format
#print("\nFinal Evaluation Metrics:")
#for name, value in zip(metrics_names, evaluation):
#    print(f"{name}: {value:.4f}")

import matplotlib.pyplot as plt
import numpy as np

# Select the index of the test subject (example: index 0, slice 23)
test_subject_index = 0
slice_index = 23

# Get the input image for the chosen test subject and slice
input_image = X_test[test_subject_index][slice_index]

# Ensure input image is in the range [0, 1] for grayscale display (normalize if needed)
input_image = np.clip(input_image, 0, 1)

# Get the ground truth CBF and ATT images for the chosen test subject and slice
cbf_ground_truth = y_test_cbf[test_subject_index][slice_index]
att_ground_truth = y_test_att[test_subject_index][slice_index]

# Predict the output using the trained model
cbf_pred, att_pred = model.predict(np.expand_dims(X_test[test_subject_index], axis=0))

# Extract the predicted CBF and ATT for the chosen slice
cbf_pred_slice = cbf_pred[0][slice_index]
att_pred_slice = att_pred[0][slice_index]

# Optionally normalize the predicted values if required
# cbf_pred_slice = np.clip(cbf_pred_slice, 0, 1)
# att_pred_slice = np.clip(att_pred_slice, 0, 1)

# Create a plot to show the reference image, input image, and output CBF and ATT
fig, axes = plt.subplots(1, 5, figsize=(25, 5))

# Plot reference CBF image (ground truth CBF)
axes[0].imshow(cbf_ground_truth, cmap='gray', interpolation='none')
axes[0].set_title('CBF Ground Truth (Reference)')
axes[0].axis('off')

# Plot reference ATT image (ground truth ATT)
axes[1].imshow(att_ground_truth, cmap='gray', interpolation='none')
axes[1].set_title('ATT Ground Truth (Reference)')
axes[1].axis('off')

# Plot input image
axes[2].imshow(input_image, cmap='gray', interpolation='none')
axes[2].set_title('Input Image')
axes[2].axis('off')

# Plot predicted CBF image
axes[3].imshow(cbf_pred_slice, cmap='gray', interpolation='none')
axes[3].set_title('Predicted CBF')
axes[3].axis('off')

# Plot predicted ATT image
axes[4].imshow(att_pred_slice, cmap='gray', interpolation='none')
axes[4].set_title('Predicted ATT')
axes[4].axis('off')

plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Select the index of the test subject (example: index 0, slice 23)
test_subject_index = 0
slice_index = 23

# Get the input image for the chosen test subject and slice
input_image = X_test[test_subject_index][slice_index]

# Normalize input image for display
input_image = np.clip(input_image, 0, 1)

# Get the ground truth CBF and ATT images for the chosen test subject and slice
cbf_ground_truth = y_test_cbf[test_subject_index][slice_index]
att_ground_truth = y_test_att[test_subject_index][slice_index]

# Predict the output using the trained model
cbf_pred, att_pred = model.predict(np.expand_dims(X_test[test_subject_index], axis=0))

# Extract the predicted CBF and ATT for the chosen slice
cbf_pred_slice = cbf_pred[0][slice_index]
att_pred_slice = att_pred[0][slice_index]

# Create a plot to show the reference image, input image, and output CBF and ATT
fig, axes = plt.subplots(1, 5, figsize=(25, 5))

# Define a colormap (e.g., 'jet', 'turbo', 'viridis')
colormap = 'jet'

# Plot reference CBF image (ground truth CBF)
axes[0].imshow(cbf_ground_truth, cmap=colormap, interpolation='none')
axes[0].set_title('CBF Ground Truth (Reference)')
axes[0].axis('off')

# Plot reference ATT image (ground truth ATT)
axes[1].imshow(att_ground_truth, cmap=colormap, interpolation='none')
axes[1].set_title('ATT Ground Truth (Reference)')
axes[1].axis('off')

# Plot input image
axes[2].imshow(input_image, cmap=colormap, interpolation='none')
axes[2].set_title('Input Image')
axes[2].axis('off')

# Plot predicted CBF image
axes[3].imshow(cbf_pred_slice, cmap=colormap, interpolation='none')
axes[3].set_title('Predicted CBF')
axes[3].axis('off')

# Plot predicted ATT image
axes[4].imshow(att_pred_slice, cmap=colormap, interpolation='none')
axes[4].set_title('Predicted ATT')
axes[4].axis('off')

plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Select the test subject index
test_subject_index = 0

# Select the slices to visualize
slices = [19, 23, 26]

# Create a figure with subplots
fig, axes = plt.subplots(1, len(slices), figsize=(15, 5))

# Plot each slice
for i, slice_index in enumerate(slices):
    input_image = X_test[test_subject_index][slice_index]

    # Ensure the image is grayscale (in case it has multiple channels)
    if input_image.ndim == 3:  # If it's a color image, take the mean across channels
        input_image = np.mean(input_image, axis=-1)

    # Normalize to [0, 1] if required
    input_image = np.clip(input_image, 0, 1)

    # Display the image
    axes[i].imshow(input_image, cmap='gray', interpolation='none')
    axes[i].set_title(f'Slice {slice_index}')
    axes[i].axis('off')

plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Select the index of the test subject (example: index 0, slice 23)
test_subject_index = 0
slice_index = 23

# Get the input image for the chosen test subject and slice
input_image = X_test[test_subject_index][slice_index]

# Normalize input image for display
input_image = np.clip(input_image, 0, 1)

# Get the ground truth CBF and ATT images for the chosen test subject and slice
cbf_ground_truth = y_test_cbf[test_subject_index][slice_index]
att_ground_truth = y_test_att[test_subject_index][slice_index]

# Predict the output using the trained model
cbf_pred, att_pred = model.predict(np.expand_dims(X_test[test_subject_index], axis=0))

# Extract the predicted CBF and ATT for the chosen slice
cbf_pred_slice = cbf_pred[0][slice_index]
att_pred_slice = att_pred[0][slice_index]

# Create a plot to show the reference image, input image, and output CBF and ATT
fig, axes = plt.subplots(1, 5, figsize=(25, 5))

# Set colormap to grayscale
colormap = 'gray'

# Plot reference CBF image (ground truth CBF)
axes[0].imshow(cbf_ground_truth, cmap=colormap, interpolation='none')
axes[0].set_title('CBF Ground Truth (Reference)')
axes[0].axis('off')

# Plot reference ATT image (ground truth ATT)
axes[1].imshow(att_ground_truth, cmap=colormap, interpolation='none')
axes[1].set_title('ATT Ground Truth (Reference)')
axes[1].axis('off')

# Plot input image
axes[2].imshow(input_image, cmap=colormap, interpolation='none')
axes[2].set_title('Input Image')
axes[2].axis('off')

# Plot predicted CBF image
axes[3].imshow(cbf_pred_slice, cmap=colormap, interpolation='none')
axes[3].set_title('Predicted CBF')
axes[3].axis('off')

# Plot predicted ATT image
axes[4].imshow(att_pred_slice, cmap=colormap, interpolation='none')
axes[4].set_title('Predicted ATT')
axes[4].axis('off')

plt.show()