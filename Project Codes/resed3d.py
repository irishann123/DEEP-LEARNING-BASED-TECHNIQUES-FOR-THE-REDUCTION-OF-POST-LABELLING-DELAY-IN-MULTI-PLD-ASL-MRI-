# -*- coding: utf-8 -*-
"""ResED3D.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oB9i-3gTckJwEIRRJUO-xlheVRfZLMwm
"""

import os  # Import the os module to use listdir

# Update the data path to your local path
data_path = '/home/labadmin/multiPLD/mridata'

# Check if the directory exists
if os.path.exists(data_path):
    print(f"Path '{data_path}' exists.")
    # List the files in the directory
    files = os.listdir(data_path)  # Get the list of files
    if files:
        print("Files in dataset folder:", files)
    else:
        print("The folder is empty.")
else:
    print(f"Path '{data_path}' does not exist. Please check the directory path.")

# Function to load and preprocess data
def load_and_preprocess_hdf5(file_path):
    with h5py.File(file_path, 'r') as file:
        data_group = file['data_phantom_noisy']

        # Load datasets
        pwi = np.array(data_group['PWI_images'])  # Shape: (3, 60, 60, 72)
        cbf = np.array(data_group['CBF_groundtruth'])  # Shape: (60, 60, 72)
        att = np.array(data_group['ATT_groundtruth'])  # Shape: (60, 60, 72)

        # Transpose PWI to match (batch, height, width, channels)
        pwi = np.transpose(pwi, (1, 2, 3, 0))

        # Normalize PWI, CBF, and ATT
        pwi = (pwi - np.min(pwi)) / (np.max(pwi) - np.min(pwi))
        cbf = (cbf - np.min(cbf)) / (np.max(cbf) - np.min(cbf))
        att = (att - np.min(att)) / (np.max(att) - np.min(att))

    return pwi, cbf, att

import os
import numpy as np
import h5py

# Load and preprocess data

pwi_subjects, cbf_subjects, att_subjects = [], [], []
for file_name in files:
    file_path = os.path.join(data_path, file_name)
    pwi, cbf, att = load_and_preprocess_hdf5(file_path)
    pwi_subjects.append(pwi)
    cbf_subjects.append(cbf)
    att_subjects.append(att)

# Convert lists to numpy arrays
pwi_subjects = np.array(pwi_subjects)
cbf_subjects = np.array(cbf_subjects)
att_subjects = np.array(att_subjects)

import numpy as np
import sklearn
print("NumPy version:", np.__version__)
print("Scikit-learn version:", sklearn.__version__)

from sklearn.model_selection import train_test_split

# Split data into training and testing sets
X_train, X_test, y_train_cbf, y_test_cbf, y_train_att, y_test_att = train_test_split(
    pwi_subjects, cbf_subjects, att_subjects, test_size=4/24, random_state=42
)

# Print shapes for verification
print("Training PWI shape:", X_train.shape)
print("Testing PWI shape:", X_test.shape)
print("Training CBF shape:", y_train_cbf.shape)
print("Testing CBF shape:", y_test_cbf.shape)
print("Training ATT shape:", y_train_att.shape)
print("Testing ATT shape:", y_test_att.shape)

import tensorflow as tf
from tensorflow.keras import layers, Model

# Define Res Block using a simple residual connection
class ResBlock(layers.Layer):
    def __init__(self, filters):
        super(ResBlock, self).__init__()
        self.conv1 = layers.Conv3D(filters, (3,3,3), padding="same", activation="relu")
        self.conv2 = layers.Conv3D(filters, (3,3,3), padding="same", activation="linear")

    def call(self, inputs):
        dx = self.conv1(inputs)
        dx = self.conv2(dx)
        return inputs + dx  # Residual connection step

# Define Res-based Encoder-Decoder Model
def res_model(input_shape):
    inputs = layers.Input(shape=input_shape)

    # Encoder with Res blocks
    x = layers.Conv3D(32, (3,3,3), activation="relu", padding="same")(inputs)
    x = ResBlock(32)(x)
    x = layers.MaxPooling3D((2,2,2))(x)

    x = layers.Conv3D(64, (3,3,3), activation="relu", padding="same")(x)
    x = ResBlock(64)(x)
    x = layers.MaxPooling3D((2,2,2))(x)

    x = layers.Conv3D(128, (3,3,3), activation="relu", padding="same")(x)
    x = ResBlock(128)(x)

    # Decoder
    x = layers.Conv3DTranspose(64, (2,2,2), strides=(2,2,2), padding="same")(x)
    x = ResBlock(64)(x)

    x = layers.Conv3DTranspose(32, (2,2,2), strides=(2,2,2), padding="same")(x)
    x = ResBlock(32)(x)

    # Output layers for CBF and ATT
    output_cbf = layers.Conv3D(1, (1,1,1), activation="linear", name="CBF")(x)
    output_att = layers.Conv3D(1, (1,1,1), activation="linear", name="ATT")(x)

    model = Model(inputs, [output_cbf, output_att])
    return model

# Initialize and print model
input_shape = (60, 60, 72, 3)
model = res_model(input_shape)
print(model.summary())

# SSIM and PSNR metrics functions
def ssim_loss(y_true, y_pred):
    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

def psnr_loss(y_true, y_pred):
    return tf.reduce_mean(tf.image.psnr(y_true, y_pred, max_val=1.0))

def accuracy_metric(y_true, y_pred, threshold=0.5):
    if y_pred.shape[-1] == 1:  # Only squeeze if last dimension is 1
        y_pred = tf.squeeze(y_pred, axis=-1)

    y_pred = tf.cast(y_pred > threshold, tf.float32)  # Apply threshold
    correct = tf.equal(y_true, y_pred)
    return tf.reduce_mean(tf.cast(correct, tf.float32))


def ssim_metric(y_true, y_pred):
    # Ensure y_pred has the correct shape before computing SSIM
    if y_pred.shape[-1] == 1:  # Only squeeze if the last dimension is 1
        y_pred = tf.squeeze(y_pred, axis=-1)

    return tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

def psnr_metric(y_true, y_pred):
    # Ensure y_pred has the correct shape before processing
    if y_pred.shape[-1] == 1:
        y_pred = tf.squeeze(y_pred, axis=-1)  # Squeeze only if last dim is 1

    return tf.image.psnr(y_true, y_pred, max_val=1.0)

# Lin's Concordance Correlation Coefficient (CCC)
def ccc_metric(y_true, y_pred):
    # Flatten the tensors to 1D arrays for computation
    y_true_flat = tf.reshape(y_true, [-1])
    y_pred_flat = tf.reshape(y_pred, [-1])

    # Mean of the true and predicted values
    mean_true = tf.reduce_mean(y_true_flat)
    mean_pred = tf.reduce_mean(y_pred_flat)

    # Covariance between true and predicted
    covariance = tf.reduce_mean((y_true_flat - mean_true) * (y_pred_flat - mean_pred))

    # Variance of the true and predicted values
    var_true = tf.reduce_mean(tf.square(y_true_flat - mean_true))
    var_pred = tf.reduce_mean(tf.square(y_pred_flat - mean_pred))

    # Calculate CCC
    ccc = (2 * covariance) / (var_true + var_pred + tf.square(mean_true - mean_pred))

    return ccc

# Re-compile the model with the added metrics, including ccc_metric
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss={'CBF': 'mean_squared_error', 'ATT': 'mean_squared_error'},
    metrics={
        'CBF': ['mse', ssim_metric, psnr_metric, accuracy_metric, ccc_metric],
        'ATT': ['mse', ssim_metric, psnr_metric, accuracy_metric, ccc_metric]
    }
)

# Training the model
history = model.fit(
    X_train, [y_train_cbf, y_train_att],
    validation_data=(X_test, [y_test_cbf, y_test_att]),
    epochs=2000,
    batch_size=2,
    verbose=1
)

# Get metric names
metric_names = model.metrics_names

# Evaluate the model
evaluation = model.evaluate(X_test, [y_test_cbf, y_test_att], verbose=1)

# Create a dictionary mapping metric names to values
evaluation_dict = dict(zip(metric_names, evaluation))

# Print the required metrics
print(f"CBF MSE: {evaluation_dict['CBF_mse']:.6f}, ATT MSE: {evaluation_dict['ATT_mse']:.6f}")
print(f"CBF SSIM: {evaluation_dict['CBF_ssim_metric']:.6f}, ATT SSIM: {evaluation_dict['ATT_ssim_metric']:.6f}")
print(f"CBF PSNR: {evaluation_dict['CBF_psnr_metric']:.6f}, ATT PSNR: {evaluation_dict['ATT_psnr_metric']:.6f}")
print(f"CBF CCC: {evaluation_dict['CBF_ccc_metric']:.6f}, ATT CCC: {evaluation_dict['ATT_ccc_metric']:.6f}")


# Extract the metrics from evaluation results
#metrics_names = [
#   "CBF_Loss", "CBF_MSE", "ATT_MSE", "CBF_Accuracy", "ATT_Accuracy",
#    "CBF_PSNR", "ATT_PSNR", "CBF_SSIM", "ATT_SSIM"
#]

# Print metrics in a readable format
#print("\nFinal Evaluation Metrics:")
#for name, value in zip(metrics_names, evaluation):
#    print(f"{name}: {value:.4f}")

import matplotlib.pyplot as plt
import numpy as np

# Select the index of the test subject (example: index 0, slice 23)
test_subject_index = 0
slice_index = 23

# Get the input image for the chosen test subject and slice
input_image = X_test[test_subject_index][slice_index]

# Normalize input image for display
input_image = np.clip(input_image, 0, 1)

# Get the ground truth CBF and ATT images for the chosen test subject and slice
cbf_ground_truth = y_test_cbf[test_subject_index][slice_index]
att_ground_truth = y_test_att[test_subject_index][slice_index]

# Predict the output using the trained model
cbf_pred, att_pred = model.predict(np.expand_dims(X_test[test_subject_index], axis=0))

# Extract the predicted CBF and ATT for the chosen slice
cbf_pred_slice = cbf_pred[0][slice_index]
att_pred_slice = att_pred[0][slice_index]

# Create a plot to show the reference image, input image, and output CBF and ATT
fig, axes = plt.subplots(1, 5, figsize=(25, 5))

# Define a colormap (e.g., 'jet', 'turbo', 'viridis')
colormap = 'jet'

# Plot reference CBF image (ground truth CBF)
axes[0].imshow(cbf_ground_truth, cmap=colormap, interpolation='none')
axes[0].set_title('CBF Ground Truth (Reference)')
axes[0].axis('off')

# Plot reference ATT image (ground truth ATT)
axes[1].imshow(att_ground_truth, cmap=colormap, interpolation='none')
axes[1].set_title('ATT Ground Truth (Reference)')
axes[1].axis('off')

# Plot input image
axes[2].imshow(input_image, cmap=colormap, interpolation='none')
axes[2].set_title('Input Image')
axes[2].axis('off')

# Plot predicted CBF image
axes[3].imshow(cbf_pred_slice, cmap=colormap, interpolation='none')
axes[3].set_title('Predicted CBF')
axes[3].axis('off')

# Plot predicted ATT image
axes[4].imshow(att_pred_slice, cmap=colormap, interpolation='none')
axes[4].set_title('Predicted ATT')
axes[4].axis('off')

plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Select the index of the test subject (example: index 0, slice 23)
test_subject_index = 0
slice_index = 23

# Get the input image for the chosen test subject and slice
input_image = X_test[test_subject_index][slice_index]

# Normalize input image for display
input_image = np.clip(input_image, 0, 1)

# Get the ground truth CBF and ATT images for the chosen test subject and slice
cbf_ground_truth = y_test_cbf[test_subject_index][slice_index]
att_ground_truth = y_test_att[test_subject_index][slice_index]

# Predict the output using the trained model
cbf_pred, att_pred = model.predict(np.expand_dims(X_test[test_subject_index], axis=0))

# Extract the predicted CBF and ATT for the chosen slice
cbf_pred_slice = cbf_pred[0][slice_index]
att_pred_slice = att_pred[0][slice_index]

# Create a plot to show the reference image, input image, and output CBF and ATT
fig, axes = plt.subplots(1, 5, figsize=(25, 5))

# Set colormap to grayscale
colormap = 'gray'

# Plot reference CBF image (ground truth CBF)
axes[0].imshow(cbf_ground_truth, cmap=colormap, interpolation='none')
axes[0].set_title('CBF Ground Truth (Reference)')
axes[0].axis('off')

# Plot reference ATT image (ground truth ATT)
axes[1].imshow(att_ground_truth, cmap=colormap, interpolation='none')
axes[1].set_title('ATT Ground Truth (Reference)')
axes[1].axis('off')

# Plot input image
axes[2].imshow(input_image, cmap=colormap, interpolation='none')
axes[2].set_title('Input Image')
axes[2].axis('off')

# Plot predicted CBF image
axes[3].imshow(cbf_pred_slice, cmap=colormap, interpolation='none')
axes[3].set_title('Predicted CBF')
axes[3].axis('off')

# Plot predicted ATT image
axes[4].imshow(att_pred_slice, cmap=colormap, interpolation='none')
axes[4].set_title('Predicted ATT')
axes[4].axis('off')

plt.show()

